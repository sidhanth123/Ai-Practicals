P1 - Write a program to implement Breadth First Search on a given dataset.

# Importing the deque class from collections to use as a queue
from collections import deque

# Creating a graph using a dictionary (adjacency list format)
graph = {
    'A': ['B', 'C'],     # Node A is connected to B and C
    'B': ['D', 'E'],     # Node B is connected to D and E
    'C': ['F'],          # Node C is connected to F
    'D': [],             # Node D has no children
    'E': ['F'],          # Node E is connected to F
    'F': []              # Node F has no children
}

# Function to perform Breadth First Search
def bfs(start_node):
    visited = set()                 # To keep track of visited nodes
    queue = deque([start_node])    # Initialize queue with the start node

    while queue:                   # Run loop until queue is empty
        node = queue.popleft()     # Remove and return the leftmost node
        if node not in visited:    # If the node has not been visited
            print(node, end=' ')   # Print the node
            visited.add(node)      # Mark the node as visited
            queue.extend(graph[node])  # Add all neighbors to the queue

# Calling the bfs function with starting node 'A'
print("BFS Traversal:")
bfs('A')



P2 - Write a program to implement Depth first search on given dataset

# Creating a graph using dictionary (adjacency list representation)
graph = {
    'A': ['B', 'C'],     # Node A connects to B and C
    'B': ['D', 'E'],     # Node B connects to D and E
    'C': ['F'],          # Node C connects to F
    'D': [],             # Node D has no children
    'E': ['F'],          # Node E connects to F
    'F': []              # Node F has no children
}

# Function to perform Depth First Search
def dfs(node, visited):
    if node not in visited:            # Check if the node is already visited
        print(node, end=' ')           # Print the current node
        visited.add(node)              # Mark the node as visited
        for neighbor in graph[node]:   # Visit all the adjacent nodes
            dfs(neighbor, visited)     # Recursive call to DFS

# Set to keep track of visited nodes
visited = set()

# Calling the dfs function with starting node 'A'
print("DFS Traversal:")
dfs('A', visited)


P3 - Solve 8-Queens Problem with suitable assumptions.

Assumption - Only one valid solution is printed.

	     The board is 8x8.

	     Queens are placed such that no two threaten each other (no same row, column, or diagonal).

# Define the size of the chessboard (8x8 for 8 queens)
N = 8

# Function to print the board
def print_board(board):
    for row in board:
        print(" ".join(str(cell) for cell in row))  # Print each row
    print()

# Function to check if it's safe to place a queen at board[row][col]
def is_safe(board, row, col):
    # Check column above
    for i in range(row):
        if board[i][col] == 1:
            return False

    # Check upper left diagonal
    for i, j in zip(range(row-1, -1, -1), range(col-1, -1, -1)):
        if board[i][j] == 1:
            return False

    # Check upper right diagonal
    for i, j in zip(range(row-1, -1, -1), range(col+1, N)):
        if board[i][j] == 1:
            return False

    return True  # It's safe to place queen

# Function to solve the problem using backtracking
def solve_queens(board, row):
    if row == N:  # All 8 queens placed
        print_board(board)  # Print the solution
        return True         # Solution found

    for col in range(N):  # Try all columns in current row
        if is_safe(board, row, col):  # Check if it's safe
            board[row][col] = 1       # Place the queen
            if solve_queens(board, row + 1):  # Move to next row
                return True
            board[row][col] = 0       # Backtrack: Remove the queen

    return False  # No solution found in this path

# Create 8x8 board filled with 0
board = [[0 for _ in range(N)] for _ in range(N)]

# Start solving from row 0
print("One solution to the 8-Queens Problem:")
solve_queens(board, 0)


P4 - Implement a program to perform tokenization, eliminate stopwords, and perform stemming using NLTK.

# Import necessary libraries from nltk
import nltk
from nltk.tokenize import word_tokenize        # For breaking sentence into words
from nltk.corpus import stopwords              # For stopword removal
from nltk.stem import PorterStemmer            # For stemming

# Download required NLTK data (only once, skip this in practical exam if already done)
# nltk.download('punkt')
# nltk.download('stopwords')

# Sample input sentence
sentence = "NLTK is a powerful Python library used for text processing tasks like tokenization, stemming and more."

# Step 1: Tokenization - Split sentence into individual words
tokens = word_tokenize(sentence)
print("Tokens:", tokens)

# Step 2: Stopword removal - Remove common words like 'is', 'for', 'and', etc.
stop_words = set(stopwords.words('english'))   # Load English stopwords
filtered_tokens = [word for word in tokens if word.lower() not in stop_words]
print("After Stopword Removal:", filtered_tokens)

# Step 3: Stemming - Reduce words to their root form
stemmer = PorterStemmer()
stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]
print("After Stemming:", stemmed_tokens)


P5 - Write a Python program to find Term Frequency and Inverse Document Frequency (TF-IDF).

# Import the TfidfVectorizer class from sklearn
from sklearn.feature_extraction.text import TfidfVectorizer

# Sample dataset: List of 3 simple documents
documents = [
    "the sky is blue",
    "the sun is bright",
    "the sun in the blue sky is bright"
]

# Create the TfidfVectorizer object
vectorizer = TfidfVectorizer()

# Fit the model and transform the documents into TF-IDF matrix
tfidf_matrix = vectorizer.fit_transform(documents)

# Get the list of unique words (features)
feature_names = vectorizer.get_feature_names_out()

# Convert the TF-IDF matrix to array form for easy printing
tfidf_array = tfidf_matrix.toarray()

# Print TF-IDF scores for each document
for i in range(len(documents)):
    print(f"\nTF-IDF scores for Document {i+1}:")
    for j in range(len(feature_names)):
        print(f"{feature_names[j]}: {tfidf_array[i][j]:.4f}")


P6 - Perform Feature extraction and analysis techniques on processed text

# Import necessary libraries
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Uncomment these lines to download stopwords (only once)
# nltk.download('punkt')
# nltk.download('stopwords')

# Sample input documents
documents = [
    "Natural Language Processing is fun and exciting!",
    "Machine Learning is a part of Artificial Intelligence.",
    "Text processing with Python is powerful."
]

# Preprocessing: remove stopwords and tokenize
def preprocess(text):
    stop_words = set(stopwords.words('english'))  # Load stopwords
    words = word_tokenize(text)                   # Tokenize the sentence
    filtered = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]
    return ' '.join(filtered)                     # Return cleaned sentence

# Apply preprocessing to all documents
processed_docs = [preprocess(doc) for doc in documents]

# Feature Extraction using CountVectorizer (Bag of Words model)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(processed_docs)

# Get feature names (unique words)
features = vectorizer.get_feature_names_out()

# Convert the matrix to array for easier analysis
X_array = X.toarray()

# Print feature matrix
print("Feature Matrix (Bag of Words):")
print(features)
print(X_array)

# Simple Analysis: word frequency in each document
for i in range(len(documents)):
    print(f"\nWord frequencies in Document {i+1}:")
    for j in range(len(features)):
        if X_array[i][j] > 0:
            print(f"{features[j]}: {X_array[i][j]}")


P7 - Implement AI algorithms for NLP analysis

(Using Naive Bayes Classifier for Text Classification)

# Import necessary libraries
from sklearn.feature_extraction.text import CountVectorizer      # For converting text to numbers
from sklearn.model_selection import train_test_split             # For splitting data into train/test
from sklearn.naive_bayes import MultinomialNB                   # Naive Bayes classifier
from sklearn.metrics import accuracy_score                      # To check model performance

# Sample dataset (text and labels)
texts = [
    "I love this movie",         # Positive
    "This is a great product",   # Positive
    "Worst experience ever",     # Negative
    "I hate this phone",         # Negative
    "Amazing camera quality",    # Positive
    "Not worth the money"        # Negative
]
labels = ['positive', 'positive', 'negative', 'negative', 'positive', 'negative']

# Step 1: Convert text to feature vectors (Bag of Words)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(texts)    # Convert texts to numeric form

# Step 2: Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)

# Step 3: Train a Naive Bayes classifier
model = MultinomialNB()
model.fit(X_train, y_train)

# Step 4: Predict on test data
predictions = model.predict(X_test)

# Step 5: Evaluate the model
print("Predictions:", predictions)
print("Accuracy:", accuracy_score(y_test, predictions))


P8 - Implement Tic-Tac-Toe game using Python

# Create the board as a list of 9 empty spaces
board = [" " for _ in range(9)]

# Function to print the board
def print_board():
    print("\n")
    print(board[0] + " | " + board[1] + " | " + board[2])
    print("--+---+--")
    print(board[3] + " | " + board[4] + " | " + board[5])
    print("--+---+--")
    print(board[6] + " | " + board[7] + " | " + board[8])
    print("\n")

# Function to check if a player has won
def check_winner(player):
    # All winning combinations (rows, columns, diagonals)
    win_conditions = [
        [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rows
        [0, 3, 6], [1, 4, 7], [2, 5, 8],  # columns
        [0, 4, 8], [2, 4, 6]              # diagonals
    ]
    for condition in win_conditions:
        if board[condition[0]] == board[condition[1]] == board[condition[2]] == player:
            return True
    return False

# Function to check for a tie
def check_tie():
    return " " not in board  # If no empty spaces left, it's a tie

# Main game loop
def play_game():
    current_player = "X"
    while True:
        print_board()
        try:
            move = int(input(f"Player {current_player}, enter your move (1-9): ")) - 1
            if board[move] == " ":
                board[move] = current_player  # Make the move
                if check_winner(current_player):
                    print_board()
                    print(f"Player {current_player} wins!")
                    break
                elif check_tie():
                    print_board()
                    print("It's a tie!")
                    break
                # Switch players
                current_player = "O" if current_player == "X" else "X"
            else:
                print("That space is already taken. Try again.")
        except (ValueError, IndexError):
            print("Invalid input. Please enter a number between 1 and 9.")

# Start the game
play_game()

